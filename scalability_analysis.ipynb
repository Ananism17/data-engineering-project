{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b66988be-38b2-47a2-b3c8-036e055bc829",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import csv\n",
    "from io import StringIO\n",
    "from pyspark import SparkFiles\n",
    "from pyspark.sql.functions import col as spark_col, mean, stddev, max, min, sum, desc, when, lit, monotonically_increasing_id, abs, collect_list, size\n",
    "from pyspark.sql.types import *\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from functools import reduce\n",
    "from operator import add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9d4f86c-2559-4d0a-8ed4-78abd83c3fa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/03/20 00:25:24 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master(\"spark://192.168.2.156:7077\") \\\n",
    "    .appName(\"group_30_project\") \\\n",
    "    .config(\"spark.dynamicAllocation.enabled\", True) \\\n",
    "    .config(\"spark.dynamicAllocation.shuffleTracking.enabled\", True) \\\n",
    "    .config(\"spark.shuffle.service.enabled\", False) \\\n",
    "    .config(\"spark.dynamicAllocation.executorIdleTimeout\", \"30s\") \\\n",
    "    .config(\"spark.executor.cores\", 4) \\\n",
    "    .config(\"spark.dynamicAllocation.maxExecutors\", 1) \\\n",
    "    .config(\"spark.sql.shuffle.partitions\", 100) \\\n",
    "    .config(\"spark.driver.port\",9999)\\\n",
    "    .config(\"spark.blockManager.port\",10005)\\\n",
    "    .getOrCreate()\n",
    "# RDD API\n",
    "spark_context = spark.sparkContext\n",
    "spark_context.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76daef02-6f13-4ce6-9866-1331eabd0bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the file to SparkFiles\n",
    "spark_context.addFile(\"/home/ubuntu/millionsong_subset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca82e42e-826e-460c-a075-041f5cf28044",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to read the file on the driver node\n",
    "def func_read_csv(iterator):\n",
    "    # This will read the file from the driver's local filesystem\n",
    "    with open(SparkFiles.get(\"millionsong_subset.csv\"), 'r') as f:\n",
    "        # Read the whole file as a string\n",
    "        csv_data = f.read()\n",
    "    return [csv_data]  # Return as a list with one item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bdd7bed5-d667-41f8-91cf-50d206406c7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# Read the CSV file on the driver\n",
    "csv_content = spark_context.parallelize([1]).mapPartitions(func_read_csv).collect()[0]\n",
    "\n",
    "# Convert the CSV string to a pandas DataFrame\n",
    "# Use StringIO to make the string act like a file\n",
    "pandas_df = pd.read_csv(StringIO(csv_content), header=0)\n",
    "\n",
    "# Convert pandas DataFrame to Spark DataFrame\n",
    "df = spark.createDataFrame(pandas_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "baf3fd27-3ba4-426a-90f0-294dbdde4310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- song_id: string (nullable = true)\n",
      " |-- artist_id: string (nullable = true)\n",
      " |-- artist_name: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- tempo: double (nullable = true)\n",
      " |-- loudness: double (nullable = true)\n",
      " |-- danceability: double (nullable = true)\n",
      " |-- energy: double (nullable = true)\n",
      " |-- duration: double (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------------------+----------------+----------------+-------+--------+------------+------+---------+\n",
      "|           song_id|         artist_id|     artist_name|           title|  tempo|loudness|danceability|energy| duration|\n",
      "+------------------+------------------+----------------+----------------+-------+--------+------------+------+---------+\n",
      "|SOMZWCG12A8C13C480|ARD7TVE1187B99BFB1|          Casual|I Didn't Mean To| 92.198| -11.197|         0.0|   0.0|218.93179|\n",
      "|SOCIWDW12A8C13D406|ARMJAGH1187FB546F3|    The Box Tops|       Soul Deep|121.274|  -9.843|         0.0|   0.0|148.03546|\n",
      "|SOXVLOJ12AB0189215|ARKRRTF1187B9984DA|Sonora Santanera| Amor De Cabaret| 100.07|  -9.689|         0.0|   0.0|177.47546|\n",
      "|SONHOTT12A8C13493C|AR7G5I41187FB4CE6C|        Adam Ant| Something Girls|119.293|  -9.013|         0.0|   0.0|233.40363|\n",
      "|SOFSOCN12A8C143F5D|ARXR32B1187FB57099|             Gob|  Face the Ashes|129.738|  -4.501|         0.0|   0.0|209.60608|\n",
      "+------------------+------------------+----------------+----------------+-------+--------+------------+------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display schema and sample data\n",
    "df.printSchema()\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d2beac7-0655-4057-816d-23fc38e8d8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def duplicate_spark_df(df, repetitions=10):\n",
    "    \"\"\"Duplicates a Spark DataFrame a specified number of times.\"\"\"\n",
    "    duplicated_dfs = [df] * repetitions\n",
    "    result_df = duplicated_dfs[0]\n",
    "    for i in range(1, len(duplicated_dfs)):\n",
    "        result_df = result_df.union(duplicated_dfs[i])\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36855b90-1824-463b-b3d2-e4efef3d6207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame count: 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 5:======================================================>(119 + 1) / 120]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicated DataFrame count: 300000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "duplicated_df = duplicate_spark_df(df, repetitions=30)\n",
    "print(f\"Original DataFrame count: {df.count()}\")\n",
    "print(f\"Duplicated DataFrame count: {duplicated_df.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55eb4535-ce36-4a50-9313-2a44e3fcf9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert relevant columns to numeric if needed\n",
    "# numeric_columns = [\"tempo\", \"loudness\", \"danceability\", \"energy\", \"duration\"]\n",
    "# for col_name in numeric_columns:\n",
    "#     df = df.withColumn(col_name, df[col_name].cast(\"double\"))\n",
    "numeric_columns = [\"tempo\", \"loudness\", \"danceability\", \"energy\", \"duration\"]\n",
    "for col_name in numeric_columns:\n",
    "    duplicated_df = duplicated_df.withColumn(col_name, duplicated_df[col_name].cast(\"double\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7bd984a0-c2f6-45ee-aa96-909c77e5c828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values per column:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "song_id: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "artist_id: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "artist_name: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tempo: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loudness: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "danceability: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "energy: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 32:=====================================================>(119 + 1) / 120]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duration: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "# print(\"Missing values per column:\")\n",
    "# for col_name in df.columns:\n",
    "#     missing_count = df.filter(spark_col(col_name).isNull()).count()\n",
    "#     print(f\"{col_name}: {missing_count}\")\n",
    "print(\"Missing values per column:\")\n",
    "for col_name in duplicated_df.columns:\n",
    "    missing_count = duplicated_df.filter(spark_col(col_name).isNull()).count()\n",
    "    print(f\"{col_name}: {missing_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3004514b-eb5b-4a13-8559-c62fac838558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with missing values (if required)\n",
    "# df_clean = df.dropna()\n",
    "df_clean = duplicated_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02659ce0-5077-4e18-9ab7-1b63486979c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Z-score method for individual features\n",
    "def find_outliers_zscore(df, numeric_cols, threshold=2.5):\n",
    "    # from pyspark.sql.functions import col as spark_col, abs, when, lit\n",
    "    \n",
    "    outlier_df = df\n",
    "    for col_name in numeric_cols:\n",
    "        # Calculate statistics\n",
    "        stats = df.select(\n",
    "            mean(col_name).alias(\"mean\"),\n",
    "            stddev(col_name).alias(\"stddev\")\n",
    "        ).collect()[0]\n",
    "        \n",
    "        # Skip if standard deviation is zero\n",
    "        if stats[\"stddev\"] == 0:\n",
    "            continue\n",
    "        \n",
    "        # Calculate z-scores\n",
    "        outlier_df = outlier_df.withColumn(\n",
    "            f\"{col_name}_zscore\",\n",
    "            abs((spark_col(col_name) - stats[\"mean\"]) / stats[\"stddev\"])\n",
    "        )\n",
    "        \n",
    "        # Flag outliers\n",
    "        outlier_df = outlier_df.withColumn(\n",
    "            f\"{col_name}_is_outlier\",\n",
    "            when(spark_col(f\"{col_name}_zscore\") > threshold, 1).otherwise(0)\n",
    "        )\n",
    "    \n",
    "    # Count outlier flags per row\n",
    "    for col_name in numeric_cols:\n",
    "        if f\"{col_name}_is_outlier\" in outlier_df.columns:\n",
    "            if \"outlier_count\" not in outlier_df.columns:\n",
    "                outlier_df = outlier_df.withColumn(\"outlier_count\", spark_col(f\"{col_name}_is_outlier\"))\n",
    "            else:\n",
    "                outlier_df = outlier_df.withColumn(\n",
    "                    \"outlier_count\", \n",
    "                    spark_col(\"outlier_count\") + spark_col(f\"{col_name}_is_outlier\")\n",
    "                )\n",
    "    \n",
    "    if \"outlier_count\" not in outlier_df.columns:\n",
    "        outlier_df = outlier_df.withColumn(\"outlier_count\", lit(0))\n",
    "    \n",
    "    return outlier_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef1d330d-d27c-429e-9169-f95244db1f61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most unusual songs:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------------------+--------------------+-------------+\n",
      "|           song_id|         artist_name|               title|outlier_count|\n",
      "+------------------+--------------------+--------------------+-------------+\n",
      "|SOITEVV12A6D4F5969|The American Boyc...|Stille nacht_ hei...|            2|\n",
      "|SOABYBF12A8C138A09|        Klaus Badelt|     Severe Severing|            2|\n",
      "|SORJPQM12A8C1338BB|David Zinman;Pitt...|Concerto for Orch...|            2|\n",
      "|SODANYE12AB0182941|     R. Carlos Nakai|    Red Wind (World)|            2|\n",
      "|SOOIZES12AB018A80F|             L.A.V.I|     Mui Mal_ Animal|            2|\n",
      "|SOCIALB12AB01811A2|       Scott Glasgow|              Hunted|            2|\n",
      "|SOSZOXP12A6D4FB9A9|      Roger Reynolds|Binaural Presenta...|            2|\n",
      "|SOZZBDC12A8C146917|        Morton Gould|Fall River Legend...|            2|\n",
      "|SOITEVV12A6D4F5969|The American Boyc...|Stille nacht_ hei...|            2|\n",
      "|SOAPOVV12AB018CFC8|                Taal|              Noises|            2|\n",
      "|SOJMTNS12AB017DA66|          Smart Alex|Chinz Ninja (Rui ...|            2|\n",
      "|SOMUFQB12A81C22FA9|    Egberto Gismonti|       Carta De Amor|            2|\n",
      "|SOCQLKZ12AB0183796|               Aiden|   Black Market Hell|            2|\n",
      "|SORCBKI12AAF3B2DF2|          Kol Simcha|                 Why|            2|\n",
      "|SORNTMR12A8C13F949|Dan Shen_ Gruppo ...|Miserere: IV. Quo...|            2|\n",
      "|SOJUAQB12AAF3B5137|        Jorge Alfano|        Inti Guauqui|            2|\n",
      "|SOABYBF12A8C138A09|        Klaus Badelt|     Severe Severing|            2|\n",
      "|SODWYEY12AC468C30F|       Erik Berglund|       Endless Light|            2|\n",
      "|SOVJFWT12A6D4FA5D4|Mark Feldman_ Joh...|           Everafter|            2|\n",
      "|SOQFMJN12AB0181D3D|      Oliver Kalkofe|           Kapitel 4|            2|\n",
      "+------------------+--------------------+--------------------+-------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 57:====================================================> (117 + 3) / 120]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features most often causing outliers:\n",
      "loudness: 8130\n",
      "duration: 5970\n",
      "tempo: 4860\n",
      "Processing time for outlier detection: 55.50 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# Find Outliers\n",
    "start_time = time.time()\n",
    "df_outliers_zscore = find_outliers_zscore(df_clean, numeric_columns)\n",
    "\n",
    "# Find the most unusual songs\n",
    "unusual_songs = df_outliers_zscore.orderBy(desc(\"outlier_count\")).limit(20)\n",
    "print(\"Most unusual songs:\")\n",
    "unusual_songs.select(\"song_id\", \"artist_name\", \"title\", \"outlier_count\").show()\n",
    "\n",
    "# Find which features are most often causing outliers\n",
    "feature_outlier_counts = {}\n",
    "for col_name in numeric_columns:\n",
    "    if f\"{col_name}_is_outlier\" in df_outliers_zscore.columns:\n",
    "        outlier_count = df_outliers_zscore.filter(spark_col(f\"{col_name}_is_outlier\") == 1).count()\n",
    "        feature_outlier_counts[col_name] = outlier_count\n",
    "\n",
    "print(\"Features most often causing outliers:\")\n",
    "for feature, count in sorted(feature_outlier_counts.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"{feature}: {count}\")\n",
    "\n",
    "processing_time = time.time() - start_time\n",
    "print(f\"Processing time for outlier detection: {processing_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b17d8414-7d9e-4c05-9141-f66aeeabd757",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artists with the widest range of musical styles:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+---------------------+\n",
      "|         artist_name|song_count|style_diversity_score|\n",
      "+--------------------+----------+---------------------+\n",
      "|      Diamanda Galas|        60|    68.89089872927948|\n",
      "|Penguin Café Orch...|       180|    58.38209720604238|\n",
      "| James Newton Howard|       150|     49.7904450817003|\n",
      "|               Hinge|        60|    49.48610802627586|\n",
      "|            Bare Jr.|        90|   47.762491463587075|\n",
      "|            Galactic|       120|   46.287844535115774|\n",
      "|       Janet Jackson|       210|    45.86887870850419|\n",
      "|              Neviss|        60|    45.59803987456597|\n",
      "|             Cam'Ron|       240|    45.09548335619707|\n",
      "|    Mario Rosenstock|       390|     43.4246367619808|\n",
      "|          The Nelons|       150|    42.35694032485055|\n",
      "|              Eminem|       240|    40.85020994062773|\n",
      "|           Broadcast|       180|    40.68665576030034|\n",
      "|         Steve Smith|        60|    40.23185638596018|\n",
      "|            Schizoid|       180|     39.9221127362399|\n",
      "|        James Horner|       150|    39.39639605611825|\n",
      "|      Richard Burton|        60|    38.63057310769073|\n",
      "|      Chico Hamilton|        90|    38.10933541137706|\n",
      "|   Gonzalo Rubalcaba|       210|    37.69639711159775|\n",
      "|         Lionel Rogg|       240|   37.639445992734494|\n",
      "+--------------------+----------+---------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Processing time for artist diversity analysis: 21.32 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# Calculate the range for each artist\n",
    "start_time = time.time()\n",
    "artist_ranges = df_clean.groupBy(\"artist_id\", \"artist_name\") \\\n",
    "    .agg(\n",
    "        *[\n",
    "            (max(spark_col(c)) - min(spark_col(c))).alias(f\"{c}_range\")\n",
    "            for c in numeric_columns\n",
    "        ]\n",
    "    )\n",
    "\n",
    "# Calculate song_count using collect_list and size()\n",
    "song_counts = df_clean.groupBy(\"artist_id\").agg(collect_list(\"artist_id\").alias(\"artist_list\"))\n",
    "song_counts = song_counts.withColumn(\"song_count\", size(spark_col(\"artist_list\")))\n",
    "song_counts = song_counts.drop(\"artist_list\")\n",
    "\n",
    "# Join song_counts back to artist_ranges\n",
    "artist_ranges = artist_ranges.join(song_counts, \"artist_id\", \"left\")\n",
    "\n",
    "# Calculate a combined range score (normalized by feature)\n",
    "feature_max_ranges = df_clean.groupBy() \\\n",
    "    .agg(*[max(spark_col(c)).alias(f\"{c}_max_range\") for c in numeric_columns]) \\\n",
    "    .collect()[0]\n",
    "\n",
    "# Normalize ranges and create a combined score\n",
    "for c in numeric_columns:\n",
    "    max_range = feature_max_ranges[f\"{c}_max_range\"]\n",
    "    if max_range > 0:  # Avoid division by zero\n",
    "        artist_ranges = artist_ranges.withColumn(\n",
    "            f\"{c}_normalized_range\",\n",
    "            spark_col(f\"{c}_range\") / max_range\n",
    "        )\n",
    "    else:\n",
    "        artist_ranges = artist_ranges.withColumn(\n",
    "            f\"{c}_normalized_range\",\n",
    "            lit(0)\n",
    "        )\n",
    "\n",
    "# Sum up normalized ranges for overall diversity score\n",
    "range_cols = [f\"{c}_normalized_range\" for c in numeric_columns]\n",
    "artist_ranges = artist_ranges.withColumn(\n",
    "    \"style_diversity_score\",\n",
    "    reduce(add, [spark_col(c) for c in range_cols])\n",
    ")\n",
    "\n",
    "# Filter out artists with too few songs\n",
    "min_songs = 5\n",
    "diverse_artists = artist_ranges.filter(spark_col(\"song_count\") >= min_songs) \\\n",
    "    .orderBy(desc(\"style_diversity_score\"))\n",
    "\n",
    "print(\"Artists with the widest range of musical styles:\")\n",
    "diverse_artists.select(\"artist_name\", \"song_count\", \"style_diversity_score\").show(20)\n",
    "\n",
    "processing_time = time.time() - start_time\n",
    "print(f\"Processing time for artist diversity analysis: {processing_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0dbe70ee-8251-46c2-8669-a0ee49ef6f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop the SparkSession\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
